<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>headSize</title>
  <style>
    html, body { height: 100%; margin: 0; font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; background:#0b1020; color:#e7edf7; }
    .wrap { display:grid; place-items:center; min-height:100%; padding:24px; gap:16px; }
    .stage { position:relative; width:min(96vw, 960px); aspect-ratio:16/9; background:#111528; border-radius:16px; box-shadow: 0 10px 30px rgba(0,0,0,.35); overflow:hidden; }
    /* Change this line */
    video, canvas { position:absolute; inset:0; width:100%; height:100%; /* no object-fit */ transform:scaleX(-1); }
 
      /* mirror for selfie view */ }
    .hud { position:absolute; left:12px; bottom:12px; display:flex; gap:8px; }
    button { background:#1e2a55; color:#e7edf7; border:1px solid #2a3975; border-radius:999px; padding:10px 14px; font-weight:600; cursor:pointer; }
    button:disabled { opacity:.6; cursor:not-allowed; }
    .note { opacity:.8; font-size:14px; }
    .badge { position:absolute; right:12px; top:12px; background:#162147; padding:6px 10px; border-radius:999px; border:1px solid #293b7c; font-size:12px; }
  </style>
</head>
<body>
  <div class="wrap">
    <h1 style="margin:0;font-size:24px">headSize</h1>


    <div class="stage" id="stage">
      <video id="video" playsinline autoplay muted></video>
      <canvas id="overlay"></canvas>
      <div class="badge" id="status">loading model…</div>
      <div class="hud">
        <button id="startBtn">Start camera</button>
        <button id="stopBtn" disabled>Stop</button>
      </div>
    </div>

    <p class="note">Tip: If nothing appears, ensure camera permissions are granted. Everything runs locally in your browser.</p>
  </div>

  <!-- MediaPipe Tasks Vision bundle (includes WASM loader) -->
  <script type="module">
    // Import the MediaPipe Tasks Vision bundle from a CDN.
    import {
      FaceLandmarker,
      FilesetResolver,
      DrawingUtils
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.mjs";

    import DeviceDetector from "https://cdn.skypack.dev/device-detector-js@2.2.10";    

    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');

    let faceLandmarker = null;
    let running = false;
    let stream = null;

    

    // Resize canvas to match the displayed size of the stage
    function resizeCanvasToDisplaySize() {
      const rect = canvas.getBoundingClientRect();
      const dpr = Math.max(1, window.devicePixelRatio || 1);
      canvas.width  = Math.round(rect.width  * dpr);
      canvas.height = Math.round(rect.height * dpr);
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0); // scale drawings for crispness
    }

    function sizeToVideo() {
     const stage = document.getElementById('stage');
     const vw = video.videoWidth || 1280;
     const vh = video.videoHeight || 720;
     // Match stage to the camera’s real aspect so there’s no crop/letterbox
     stage.style.aspectRatio = `${vw} / ${vh}`;
     // Backing store == intrinsic video size (device-pixel math handled by DrawingUtils)
     canvas.width  = vw;
     canvas.height = vh;
     // Draw in raw canvas coordinates (no extra DPR scaling)
     ctx.setTransform(1, 0, 0, 1, 0, 0);
    }

    // Simple landmark drawer (or use DrawingUtils for convenience)
    const drawLandmarks = (results) => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (!results || !results.faceLandmarks) return;
      const du = new DrawingUtils(ctx);

      for (const lmks of results.faceLandmarks) {
        // ---------- helpers ----------
        const uniqIdx = (conns) => {
          const s = new Set();
          for (const seg of conns) { s.add(seg.start); s.add(seg.end); }
          return [...s];
        };
        const toPx = (p) => ({ x: p.x * canvas.width, y: p.y * canvas.height });

        // ---------- iris centers (for IPD & bridge) ----------
        const leftIrisIdx  = uniqIdx(FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS);
        const rightIrisIdx = uniqIdx(FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS);

        const center3D = (idxs) => {
          let sx = 0, sy = 0, sz = 0;
          const n = Math.max(1, idxs.length);
          for (const i of idxs) { sx += lmks[i].x; sy += lmks[i].y; sz += lmks[i].z; }
          return { x: sx / n, y: sy / n, z: sz / n };
        };

        const cL = center3D(leftIrisIdx);
        const cR = center3D(rightIrisIdx);
        const cLpx = toPx(cL), cRpx = toPx(cR);

        // ---------- IPD (px + ~mm via iris width scale) ----------
        const dx_px = cRpx.x - cLpx.x;
        const dy_px = cRpx.y - cLpx.y;
        const ipdPx = Math.hypot(dx_px, dy_px);

        const irisWidthPx = (idxs) => {
          let minX = Infinity, maxX = -Infinity;
          for (const i of idxs) {
            const px = lmks[i].x * canvas.width;
            if (px < minX) minX = px;
            if (px > maxX) maxX = px;
          }
          return Math.max(0, maxX - minX);
        };
        const leftIrisWpx  = irisWidthPx(leftIrisIdx);
        const rightIrisWpx = irisWidthPx(rightIrisIdx);
        const irisPx = (leftIrisWpx && rightIrisWpx) ? (leftIrisWpx + rightIrisWpx) / 2 : (leftIrisWpx || rightIrisWpx || 0);
        const realIrisMM = 11.7; // assumed average human iris diameter
        const mmPerPx = irisPx > 0 ? (realIrisMM / irisPx) : 0;
        const ipdMM = mmPerPx ? ipdPx * mmPerPx : 0;

        // ---------- face breadth (px) via face oval extremes ----------
        let faceMinX = Infinity, faceMaxX = -Infinity, leftPt = null, rightPt = null;
        // for (const seg of FaceLandmarker.FACE_LANDMARKS_FACE_OVAL) {
        //   const i = seg.start;
        //   const p = lmks[i];
        //   if (p.x < faceMinX) { faceMinX = p.x; leftPt = p; }
        //   if (p.x > faceMaxX) { faceMaxX = p.x; rightPt = p; }
        // }
        leftPt=lmks[127]
        faceMinX=leftPt.x
        rightPt=lmks[356]
        faceMaxX=rightPt.x
        const faceBreadthPx = (faceMaxX - faceMinX) * canvas.width;
        const faceBreadthMM = mmPerPx ? faceBreadthPx * mmPerPx : 0;
        const leftPx  = leftPt  ? toPx(leftPt)  : null;
        const rightPx = rightPt ? toPx(rightPt) : null;

        // ---------- nose arch Δz (depth) ----------
        // Bridge = midpoint of iris centers (in 3D normalized coords)
        const bridge = lmks[6]
        // { x: (cL.x + cR.x) / 2, y: (cL.y + cR.y) / 2, z: (cL.z + cR.z) / 2 };
        const bridgePx = toPx(bridge);

        // Nose tip = landmark #4
        const noseTip = lmks[4];
        const noseTipPx = toPx(noseTip);

        const alareL = lmks[64];
        const alareLPx = toPx(alareL);

        const alareR = lmks[294];
        const alareRPx = toPx(alareR);

        // Δz in normalized units (|tip.z - bridge.z|)
        const deltaZ = noseTip.z - bridge.z;  // >0 means tip farther from camera
        const noseArchZAbs = Math.abs(deltaZ);

        // Optional rough mm for Δz using normalized iris width scale
        // (use normalized x extent of LEFT iris to build a norm→mm scale)
        let liMinXn = Infinity, liMaxXn = -Infinity;
        for (const i of leftIrisIdx) {
          const x = lmks[i].x; // normalized
          if (x < liMinXn) liMinXn = x;
          if (x > liMaxXn) liMaxXn = x;
        }
        const irisWidthNorm = Math.max(0, liMaxXn - liMinXn);
        const mmPerNorm = irisWidthNorm > 0 ? (realIrisMM / irisWidthNorm) : 0;
        const noseArchMM = mmPerNorm ? noseArchZAbs * mmPerNorm : 0;


        // 2D vectors in pixel space
        const vL2 = { x: alareLPx.x - noseTipPx.x, y: alareLPx.y - noseTipPx.y };
        const vR2 = { x: alareRPx.x - noseTipPx.x, y: alareRPx.y - noseTipPx.y };

        // Stable 2D angle between vectors (radians ∈ [0, π])
        const angleBetween2D = (u, v) => {
          const dot   = u.x * v.x + u.y * v.y;
          const cross = u.x * v.y - u.y * v.x;
          return Math.atan2(Math.abs(cross), dot);
        };
        const flareRad2D = angleBetween2D(vL2, vR2);
        const flareDeg2D = (flareRad2D * 180) / Math.PI;

        ctx.save();
        ctx.scale(-1, 1);
        ctx.fillStyle = "red";
        ctx.font = "30px Arial";
        ctx.fillText(`IPD≈ ${ipdMM.toFixed(1)} mm`, -canvas.width * 0.75, canvas.height-170); 
        ctx.fillStyle = "green";
        ctx.fillText(`Face breadth≈ ${faceBreadthMM.toFixed(1)} mm`, -canvas.width * 0.75, canvas.height-130); 
        ctx.fillStyle = "blue";
        ctx.fillText(`Nose arch height≈ ${noseArchMM.toFixed(1)} mm`, -canvas.width * 0.75, canvas.height-90);
        ctx.fillStyle = "orange";
        ctx.fillText(`Nose angle≈ ${flareDeg2D.toFixed(1)} deg`, -canvas.width * 0.75, canvas.height-50);          
        ctx.restore();


        // IPD line

        ctx.fillStyle = "red";
        ctx.strokeStyle = "red";   
        ctx.lineWidth = 1;         

        ctx.beginPath();
        ctx.moveTo(cLpx.x, cLpx.y);
        ctx.lineTo(cRpx.x, cRpx.y);
        ctx.stroke();

        // Iris center dots
        ctx.beginPath(); ctx.arc(cLpx.x, cLpx.y, 4, 0, Math.PI * 2); ctx.fill();
        ctx.beginPath(); ctx.arc(cRpx.x, cRpx.y, 4, 0, Math.PI * 2); ctx.fill();

        // Face breadth line (connect detected extreme oval points)
        ctx.fillStyle = "green";
        ctx.strokeStyle = "green";   
        ctx.lineWidth = 1;         
        if (leftPt && rightPt) {
          ctx.beginPath();
          ctx.moveTo(leftPx.x, leftPx.y);
          ctx.lineTo(rightPx.x, rightPx.y);
          ctx.stroke();

          // small markers
          ctx.beginPath(); ctx.arc(leftPx.x,  leftPx.y, 3, 0, Math.PI * 2); ctx.fill();
          ctx.beginPath(); ctx.arc(rightPx.x, rightPx.y, 3, 0, Math.PI * 2); ctx.fill();
        }

        // Nose arch line: bridge proxy -> lowest central point
        ctx.fillStyle = "blue";
        ctx.strokeStyle = "blue";   
        ctx.lineWidth = 1; 
        ctx.beginPath();
        ctx.moveTo(bridgePx.x, bridgePx.y);
        ctx.lineTo(noseTipPx.x, noseTipPx.y);
        ctx.stroke();

        // Dots at bridge and nose tip
        ctx.beginPath(); ctx.arc(bridgePx.x,   bridgePx.y,   3, 0, Math.PI * 2); ctx.fill();
        ctx.beginPath(); ctx.arc(noseTipPx.x,  noseTipPx.y,  3, 0, Math.PI * 2); ctx.fill();



        ctx.fillStyle = "orange"; ctx.fill();
        ctx.beginPath(); ctx.arc(alareLPx.x,  alareLPx.y,  3, 0, Math.PI*2); ctx.fill();
        ctx.beginPath(); ctx.arc(alareRPx.x,  alareRPx.y,  3, 0, Math.PI*2); ctx.fill();
        
        // Small arc at the tip to visualize the angle
        const aL = Math.atan2(vL2.y, vL2.x);
        const aR = Math.atan2(vR2.y, vR2.x);
        // choose a reasonable radius based on shortest leg
        const rArc = Math.max(20, Math.min(80, Math.min(Math.hypot(vL2.x, vL2.y), Math.hypot(vR2.x, vR2.y)) * 0.35));
        let d = ((aR - aL + Math.PI*3) % (Math.PI*2)) - Math.PI; // normalize to (-π, π]
        ctx.beginPath();
        ctx.arc(noseTipPx.x, noseTipPx.y, rArc, aL, aR, d < 0); // draw along the shorter direction
        ctx.strokeStyle = "orange";
        ctx.lineWidth = 2;
        ctx.stroke();        

        // Connections: Use DrawingUtils to draw tesselation and contours
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_TESSELATION, { lineWidth: 0.5 });
        du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, { lineWidth: 1.5 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW, { lineWidth: 1 });
        du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, { lineWidth: 1.5 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW, { lineWidth: 1 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_FACE_OVAL, { lineWidth: 1.25 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_LIPS, { lineWidth: 1.25 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS, { lineWidth: 1.25 });
        // du.drawConnectors(lmks, FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS, { lineWidth: 1.25 });



      }
    };

    async function createLandmarker() {
      // Load the WASM fileset
      const fileset = await FilesetResolver.forVisionTasks(
        // The bundle hosts these paths internally; CDN provides them as relative assets
        // so no extra config is necessary here
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );

      // Use Google's hosted .task model (float16, 1 face). You can swap to int8 for smaller size.
      // Other options are available (see model cards); this URL is public.
      faceLandmarker = await FaceLandmarker.createFromOptions(fileset, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        },
        runningMode: "VIDEO",
        numFaces: 1,
        outputFaceBlendshapes: false,
        outputFacialTransformationMatrixes: false
      });
      statusEl.textContent = 'model ready';
    }

    async function startCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = stream;
        await video.play();

        // Ensure metadata is loaded so videoWidth/Height are correct
        if (video.readyState < 2) {
          await new Promise(res => video.addEventListener('loadedmetadata', res, { once: true }));
        }

        sizeToVideo();
        window.addEventListener('resize', sizeToVideo);

        running = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        statusEl.textContent = 'running';
        loop();
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'camera error (check permissions)';
      }
    }

    function stopCamera() {
      running = false;
      if (stream) {
        for (const t of stream.getTracks()) t.stop();
        stream = null;
      }
      startBtn.disabled = false;
      stopBtn.disabled = true;
      statusEl.textContent = 'stopped';
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    async function loop() {
      if (!running || !faceLandmarker || video.readyState < 2) {
        if (running) requestAnimationFrame(loop);
        return;
      }

      const nowMs = performance.now();
      const results = faceLandmarker.detectForVideo(video, nowMs);
      drawLandmarks(results);
      requestAnimationFrame(loop);
    }

    // Wire up UI
    startBtn.addEventListener('click', () => {
      if (!faceLandmarker) {
        statusEl.textContent = 'loading model…';
        createLandmarker().then(startCamera).catch((e) => {
          console.error(e);
          statusEl.textContent = 'failed to load model';
        });
      } else {
        startCamera();
      }
    });

    stopBtn.addEventListener('click', stopCamera);

    // Optional: Preload model so first click is instant
    createLandmarker().catch((e) => {
      console.warn('Model preload failed:', e);
      statusEl.textContent = 'click Start camera';
    });

    startCamera();
  </script>
</body>
</html>
